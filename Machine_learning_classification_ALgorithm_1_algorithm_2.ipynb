{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkP0C4mfB8Bj",
        "outputId": "47c31abf-8fa3-49eb-8f11-3901b0f43cec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 8 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre-headless amd64 8u372-ga~us1-0ubuntu1~22.04 [30.8 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jdk-headless amd64 8u372-ga~us1-0ubuntu1~22.04 [8,860 kB]\n",
            "Fetched 39.7 MB in 2s (23.5 MB/s)\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 129824 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u372-ga~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u372-ga~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u372-ga~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u372-ga~us1-0ubuntu1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u372-ga~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u372-ga~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install openjdk-8-jdk-headless"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installing hadoop\n",
        "!wget https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5gd5MqeCgP_",
        "outputId": "82cb910b-d6f4-4d9e-a904-0936d3247355"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-23 12:51:32--  https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 65.108.204.189, 2a01:4f9:1a:a084::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|65.108.204.189|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 272637746 (260M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.2.1-bin-hadoop2.7.tgz’\n",
            "\n",
            "spark-3.2.1-bin-had 100%[===================>] 260.01M  18.8MB/s    in 15s     \n",
            "\n",
            "2023-07-23 12:51:47 (17.4 MB/s) - ‘spark-3.2.1-bin-hadoop2.7.tgz’ saved [272637746/272637746]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unzinpping the folder\n",
        "!tar xf /content/spark-3.2.1-bin-hadoop2.7.tgz"
      ],
      "metadata": {
        "id": "eXOAHdyQCn5F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installing findspark library\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "dGUiuF1nCu2F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop2.7\""
      ],
      "metadata": {
        "id": "4ML60PlDC2-O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# locating spark system\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8SyytgSdC5GN",
        "outputId": "662b15d1-c2da-467a-f891-628de5214da6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-3.2.1-bin-hadoop2.7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the emvoironment\n",
        "import pyspark\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "VEJae6dADPDE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.context import SparkContext\n",
        "from pyspark.sql.session import SparkSession\n",
        "sc = SparkContext.getOrCreate();\n",
        "spark = SparkSession(sc)"
      ],
      "metadata": {
        "id": "NY140fRedSIk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "kYIECFA5DjBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flamingo = spark.read.csv('/content/drive/MyDrive/Big Data Management/datasets/flamingo-data/game-clicks.csv', sep=',', header=True, inferSchema=True, nullValue='NA')\n",
        "\n",
        "flamingo.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCdeAJTSDZ4w",
        "outputId": "ab64377c-23e2-49db-b1a6-a01e83acc0f5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------+---------+----------+-----+\n",
            "|     timestamp|clickId|teamLevel|count_hits|isHit|\n",
            "+--------------+-------+---------+----------+-----+\n",
            "|6/16/2016 8:11| 750154|        8|         8|    0|\n",
            "|6/16/2016 8:11| 750503|        7|         5|    0|\n",
            "|6/16/2016 8:11| 750692|        6|         2|    0|\n",
            "|6/16/2016 8:11| 750788|        4|         4|    0|\n",
            "|6/16/2016 8:11| 750133|        8|         0|    0|\n",
            "+--------------+-------+---------+----------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "flamingo.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjUlIa-a0pi3",
        "outputId": "cf10b17a-9554-4315-983e-7d30d00f5860"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3497"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the useless features\n",
        "flamingo1 = flamingo.drop('clickId')\n",
        "flamingo2 = flamingo1.drop('timestamp')\n",
        "\n",
        "flamingo2.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSDKiCse1ehM",
        "outputId": "543f04df-23d5-4aed-fdd5-c016244704db"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+-----+\n",
            "|teamLevel|count_hits|isHit|\n",
            "+---------+----------+-----+\n",
            "|        8|         8|    0|\n",
            "|        7|         5|    0|\n",
            "|        6|         2|    0|\n",
            "|        4|         4|    0|\n",
            "|        8|         0|    0|\n",
            "|        7|         5|    0|\n",
            "|        8|         5|    0|\n",
            "|        1|         8|    0|\n",
            "|        5|         6|    0|\n",
            "|        8|         9|    0|\n",
            "|        8|         6|    0|\n",
            "|        7|         9|    1|\n",
            "|        8|         6|    0|\n",
            "|        8|        14|    0|\n",
            "|        8|         7|    0|\n",
            "|        8|         8|    0|\n",
            "|        7|        21|    0|\n",
            "|        8|         4|    0|\n",
            "|        5|        10|    0|\n",
            "|        8|         2|    0|\n",
            "+---------+----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import round\n",
        "\n",
        "\n",
        "# Create 'label' column indicating it is a hit (1) or not(0)\n",
        "flamingo2 = flamingo2.withColumn('label', (flamingo2.isHit >= 1).cast('integer'))\n",
        "\n",
        "flamingo3 = flamingo2.drop('isHit')\n",
        "\n",
        "# Check first five records\n",
        "flamingo3.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88EwJuwZBxcN",
        "outputId": "e0174350-1986-41ec-f80b-ad35248b47a8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+-----+\n",
            "|teamLevel|count_hits|label|\n",
            "+---------+----------+-----+\n",
            "|        8|         8|    0|\n",
            "|        7|         5|    0|\n",
            "|        6|         2|    0|\n",
            "|        4|         4|    0|\n",
            "|        8|         0|    0|\n",
            "+---------+----------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YwsmJHisCqmp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Create an assembler object\n",
        "assembler = VectorAssembler(inputCols=[\n",
        "    'teamLevel', 'count_hits',\n",
        "], outputCol='features')\n",
        "\n",
        "# Consolidate predictor columns\n",
        "flamingo_assembled = assembler.transform(flamingo3)\n",
        "\n",
        "# Check the resulting column\n",
        "flamingo_assembled.select('features', 'label').show(5, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qcKguBI90hn",
        "outputId": "9680a7a3-f2c2-4678-9a58-7d75552d8396"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----+\n",
            "|features |label|\n",
            "+---------+-----+\n",
            "|[8.0,8.0]|0    |\n",
            "|[7.0,5.0]|0    |\n",
            "|[6.0,2.0]|0    |\n",
            "|[4.0,4.0]|0    |\n",
            "|[8.0,0.0]|0    |\n",
            "+---------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup the naive bayes**"
      ],
      "metadata": {
        "id": "5qJl731P0xow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#performing the train test split, this will done for the both classifiers 80 and 20\n",
        "(train, test) = flamingo_assembled.randomSplit([0.8, 0.2])"
      ],
      "metadata": {
        "id": "PtGza0Bm76DC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing the predicting model\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
        "nb = nb.fit(train)\n",
        "\n",
        "pred = nb.transform(test)\n",
        "pred.show(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUJSf_rE54wD",
        "outputId": "663940dc-0c31-4ff7-8d0c-0300bc753ed3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+-----+---------+--------------------+--------------------+----------+\n",
            "|teamLevel|count_hits|label| features|       rawPrediction|         probability|prediction|\n",
            "+---------+----------+-----+---------+--------------------+--------------------+----------+\n",
            "|        1|         0|    0|[1.0,0.0]|[-1.3061058772919...|[0.89326098705566...|       0.0|\n",
            "|        1|         2|    0|[1.0,2.0]|[-2.0270467018149...|[0.89479032542860...|       0.0|\n",
            "|        1|         2|    0|[1.0,2.0]|[-2.0270467018149...|[0.89479032542860...|       0.0|\n",
            "+---------+----------+-----+---------+--------------------+--------------------+----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now creating confusing matrix and accuracy  for the naive bayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from sklearn.metrics import confusion_matrix\n",
        "evaluator=MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
        "acc = evaluator.evaluate(pred)\n",
        "\n",
        "print(\"Prediction Accuracy: \", acc)\n",
        "\n",
        "y_pred=pred.select(\"prediction\").collect()\n",
        "y_orig=pred.select(\"label\").collect()\n",
        "\n",
        "cm = confusion_matrix(y_orig, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6rY4m9f9oLr",
        "outputId": "d5ca2823-ff81-4684-8eee-b755f8767c07"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction Accuracy:  0.8611474219317357\n",
            "Confusion Matrix:\n",
            "[[616   0]\n",
            " [ 64   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**now setup the decision tree**"
      ],
      "metadata": {
        "id": "3b8vCH0x17NU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and test sets in a 80:20 ratio\n",
        "flamingo_train, flamingo_test = flamingo_assembled.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Check that training set has around 80% of records\n",
        "training_ratio = flamingo_train.count() / flamingo_assembled.count()\n",
        "print(training_ratio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWtIq2YjAYNm",
        "outputId": "32e535cc-3062-4cf8-9fec-50932c34c188"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8149842722333429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**build decesion tree**"
      ],
      "metadata": {
        "id": "tcF8YY0vAnDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "\n",
        "# Create a classifier object and fit to the training data\n",
        "tree = DecisionTreeClassifier()\n",
        "tree_model = tree.fit(flamingo_train)\n",
        "\n",
        "# Create predictions for the testing data and take a look at the predictions\n",
        "\n",
        "prediction = tree_model.transform(flamingo_test)\n",
        "prediction.select('label', 'prediction', 'probability').show(5, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N9a8sx21dhd",
        "outputId": "5345357e-ddbe-4a5e-a219-597d4001f6d8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+----------------------------------------+\n",
            "|label|prediction|probability                             |\n",
            "+-----+----------+----------------------------------------+\n",
            "|0    |0.0       |[0.8989473684210526,0.10105263157894737]|\n",
            "|0    |0.0       |[0.8989473684210526,0.10105263157894737]|\n",
            "|0    |0.0       |[0.8989473684210526,0.10105263157894737]|\n",
            "|1    |0.0       |[0.8989473684210526,0.10105263157894737]|\n",
            "|0    |0.0       |[0.8989473684210526,0.10105263157894737]|\n",
            "+-----+----------+----------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a confusion matrix\n",
        "prediction.groupBy('label', 'prediction').count().show()\n",
        "\n",
        "# Calculate the elements of the confusion matrix\n",
        "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
        "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
        "FN = prediction.filter('prediction = 0 AND label = 1').count()\n",
        "FP = prediction.filter('prediction = 1 AND label = 0').count()\n",
        "\n",
        "# Accuracy measures the proportion of correct predictions\n",
        "accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okxQG0VcDS4O",
        "outputId": "7827aef6-7882-4426-a93d-8f79f39e62e6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----------+-----+\n",
            "|label|prediction|count|\n",
            "+-----+----------+-----+\n",
            "|    1|       0.0|   71|\n",
            "|    0|       0.0|  576|\n",
            "+-----+----------+-----+\n",
            "\n",
            "0.8902627511591963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html /content/Machine_learning_classification_ALgorithm_1_algorithm_2 (1).ipynb"
      ],
      "metadata": {
        "id": "rEciDrUiL-vP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fabe2a8c-f5eb-4da4-c6f1-a866e12c637a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `jupyter nbconvert --to html /content/Machine_learning_classification_ALgorithm_1_algorithm_2 (1).ipynb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GVy5X3HX3CXJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}